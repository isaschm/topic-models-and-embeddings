{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic_Models_and_Embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFXsrSxJlzCW",
        "colab_type": "text"
      },
      "source": [
        "#Todos\n",
        "\n",
        "\n",
        "Data\n",
        "- Load Data\n",
        "- Preprocessing? (Stop Words, Links, User Names, HTML Tags)\n",
        "\n",
        "Topic Model\n",
        "- LDA (Latent Dirichlet Allocation)\n",
        "\n",
        "\n",
        "Model Evaluation:\n",
        "- Print Results: Topics, Topic Members (e.g. nearest neighbour document) (https://asistdl.onlinelibrary.wiley.com/doi/full/10.1002/asi.23786\n",
        ")\n",
        "\n",
        "- global (topic coherence, topic diversity)\n",
        "- instance based/local\n",
        "- features\n",
        "\n",
        "\n",
        "Contextual Embeddings\n",
        "- USE (https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb#scrollTo=RUymE2l9GZfO)\n",
        "- Dimensionality reduction (PCA, (UMAP), MDS) (Curse of dimensionality)\n",
        "- Clustering (Choose method: k-means, spectral, density-based methods https://scikit-learn.org/stable/modules/clustering.html)\n",
        "- Dimensionality reduction to 2D (T-SNE, UMAP)\n",
        "- make interactive map?\n",
        "\n",
        "Model Evaluation:\n",
        "- global\n",
        "- instance based/local\n",
        "- features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO9QOLP_9DxJ",
        "colab_type": "text"
      },
      "source": [
        "##Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yedoKEB5t5ym",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "aac9fc45-5e7a-4613-a675-0af1cf2bf44e"
      },
      "source": [
        "import os\n",
        "\n",
        "os.chdir(os.path.expanduser('~'))\n",
        "import gdown\n",
        "zip_folder_name = 'youtube_comments_climate_change'\n",
        "\n",
        "shared_google_drive_link = 'https://drive.google.com/uc?id=17-eCljAzaqKwy7Fd9kXAmdmkOVSZzDeE'\n",
        "output = zip_folder_name+'.zip'\n",
        "gdown.download(shared_google_drive_link,output, quiet=False)\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "    zip_ref.extractall('')\n",
        "\n",
        "\n",
        "os.chdir(zip_folder_name) \n",
        "\n",
        "data_desciption_file = 'data_description.txt'\n",
        "\n",
        "with open(data_desciption_file,'r') as myfile:\n",
        "  f = myfile.read()\n",
        "print(f)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17-eCljAzaqKwy7Fd9kXAmdmkOVSZzDeE\n",
            "To: /root/youtube_comments_climate_change.zip\n",
            "5.32MB [00:00, 43.2MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data description\n",
            "__________________\n",
            "\n",
            "// Project\n",
            "data deluge\n",
            "\n",
            "// Data mining\n",
            "All data are extracted using the YouTube Data Tools (YTDT):\n",
            "https://tools.digitalmethods.net/netvizz/youtube/\n",
            "Specifically, comments are extracted using the video info and comments module\n",
            "https://tools.digitalmethods.net/netvizz/youtube/mod_video_info.php\n",
            "\n",
            "// Datasets\n",
            "\n",
            "- videoinfo_xE0KtLy5j8w_2018_06_26-18_32_17_comments.xlsx\n",
            "This dataset includes all text posted within the comments section of the video https://youtu.be/xE0KtLy5j8w (produced by Climate Central, featured by The Daily Conversation)\n",
            "Additional variables such as time of posting, replies, likes, etc. have been removed from the dataset.\n",
            "The comments were then coded by hand, in order to identify particular coping strategies of people making sense of the information shown in the video (sea level rise scenarios).\n",
            "\n",
            "- videoinfo_VbiRNT_gWUQ_2020_01_16-10_08_40_comments.tab\n",
            "Data gathered from the video https://youtu.be/VbiRNT_gWUQ, produced by the National Geographic, featured by  Business Insider. This is the original dataset extracted through the YTDT video info and comments module, without further additions, or deletions.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trNMZEEzL0Iy",
        "colab_type": "text"
      },
      "source": [
        "#### Display zip contents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKSKCJIS9e5q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "46158579-fee2-4845-bbfd-92dc9721e9e4"
      },
      "source": [
        "zip_ref.printdir()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Name                                             Modified             Size\n",
            "youtube_comments_climate_change/               2020-06-05 15:59:54            0\n",
            "youtube_comments_climate_change/500_comments_raw.csv 2020-04-19 14:34:02       116060\n",
            "youtube_comments_climate_change/videoinfo_VbiRNT_gWUQ_2020_01_16-10_08_40_comments.tab 2020-04-19 14:34:02      7268174\n",
            "youtube_comments_climate_change/videoinfo_VbiRNT_gWUQ_2020_01_16-10_08_40_comments.tab - videoinfo_VbiRNT_gWUQ_2020_01_16-10_08_40_comments.tab.csv 2020-04-19 14:34:02      7310945\n",
            "youtube_comments_climate_change/data_description.txt 2020-04-19 14:34:02         1178\n",
            "youtube_comments_climate_change/lda_tuning_results.csv 2020-05-13 14:45:10        13802\n",
            "youtube_comments_climate_change/500_comments_raw.xlsx 2020-04-19 14:34:02        80887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLFkUlqKLh_l",
        "colab_type": "text"
      },
      "source": [
        "### Open file as df and list columns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbU3mk83MBIH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a20b785e-5cc5-488c-cb69-340708ebdcd6"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "path = \"videoinfo_VbiRNT_gWUQ_2020_01_16-10_08_40_comments.tab - videoinfo_VbiRNT_gWUQ_2020_01_16-10_08_40_comments.tab.csv\"\n",
        "data = pd.read_csv(path, sep=\",\", encoding='utf-8')\n",
        "data = data.dropna(subset=['text', 'authorName']) # drop rows with no content\n",
        "\n",
        "list(data.columns)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id',\n",
              " 'replyCount',\n",
              " 'likeCount',\n",
              " 'publishedAt',\n",
              " 'authorName',\n",
              " 'text',\n",
              " 'authorChannelId',\n",
              " 'authorChannelUrl',\n",
              " 'isReply',\n",
              " 'isReplyTo',\n",
              " 'isReplyToName']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUFQHjNeMZc8",
        "colab_type": "text"
      },
      "source": [
        "### Removing unused columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXgvP7XXMsD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "dec83a0c-4bc8-4cf4-dc11-e5bb0c336c38"
      },
      "source": [
        "data=data.drop(['id', 'replyCount','likeCount','authorChannelUrl','authorChannelId','isReplyTo','isReplyToName'],axis=1)\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publishedAt</th>\n",
              "      <th>authorName</th>\n",
              "      <th>text</th>\n",
              "      <th>isReply</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-16 09:01:08</td>\n",
              "      <td>Lee McLellan</td>\n",
              "      <td>If all the ice melts surely the tilt of the ea...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-01-16 06:16:07</td>\n",
              "      <td>Aakash Majumdar</td>\n",
              "      <td>The scariest part of the video is the music......</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-01-15 10:50:21</td>\n",
              "      <td>Glenn Davies</td>\n",
              "      <td>New Zealand be like...&amp;quot;are we good?&amp;quot;...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-01-15 08:35:50</td>\n",
              "      <td>Shane Meyer</td>\n",
              "      <td>Step #1: Taxes... Step #2: ???... Step #3: Utopia</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-01-15 02:00:30</td>\n",
              "      <td>Rennie Allen</td>\n",
              "      <td>Strange how Hudson&amp;#39;s Bay stayed the same s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           publishedAt  ... isReply\n",
              "0  2020-01-16 09:01:08  ...       0\n",
              "1  2020-01-16 06:16:07  ...       0\n",
              "2  2020-01-15 10:50:21  ...       0\n",
              "3  2020-01-15 08:35:50  ...       0\n",
              "4  2020-01-15 02:00:30  ...       0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IUWISh1M5nz",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBgbeZOMM1TQ",
        "colab_type": "text"
      },
      "source": [
        "### Removing HTML tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz8xp8RzA4dP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1830282d-fa89-489f-fb5d-34300079b639"
      },
      "source": [
        "!pip3 install html2text"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting html2text\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/88/14655f727f66b3e3199f4467bafcc88283e6c31b562686bf606264e09181/html2text-2020.1.16-py3-none-any.whl\n",
            "Installing collected packages: html2text\n",
            "Successfully installed html2text-2020.1.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIgxEvzcM39J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "529210d3-443d-479a-d907-39381d8a3aec"
      },
      "source": [
        "from html2text import HTML2Text\n",
        "from tqdm import tqdm\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "h = HTML2Text()\n",
        "h.ignore_links = True\n",
        "\n",
        "data['text'] = data['text'].progress_apply(lambda x: h.handle(x))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 25914/25914 [00:02<00:00, 10567.36it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83BuFEGPNFO2",
        "colab_type": "text"
      },
      "source": [
        "### Removing links"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYkHxy8mND1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "http_link_pattern = r'http\\S+'\n",
        "bitly_link_pattern = r'bit.ly/\\S+'\n",
        "data['text'] = data['text'].str.replace(http_link_pattern, '')\n",
        "data['text'] = data['text'].str.replace(bitly_link_pattern, '')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzOyOY7CNa_k",
        "colab_type": "text"
      },
      "source": [
        "### Removing user names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0CY9y1z4SRL",
        "colab_type": "text"
      },
      "source": [
        "Only user names consisting of more than 3 characters are removed to avoid unintentionally joining words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NF6VqiZNfts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "keep_names = [\"earth\", \"Tide\", \"Geologist\", \"A Person\", \"Titanic\", \"adventure\", \"Sun\", \"The United States Of America\"] # user names we want to keep\n",
        "user_names = [name for name in data['authorName'].unique() if (len(name)> 3 and name not in keep_names)]\n",
        "\n",
        "data['cleaned'] = data['text'].str.replace('|'.join(map(re.escape, user_names)), '')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAUnFz727jRt",
        "colab_type": "text"
      },
      "source": [
        "## Topic Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2n_uzEX8_bs",
        "colab_type": "text"
      },
      "source": [
        "### Tokenizing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5g5idszAo26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~•@'\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('['+punctuation + ']+', ' ', text) # strip punctuation\n",
        "    text = re.sub('\\s+', ' ', text) # remove double spacing\n",
        "    text = re.sub('([0-9]+)', '', text) # remove numbers\n",
        "    return text"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZld5VNuesDn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85ff9b90-0a27-4a73-9265-500723b61a6d"
      },
      "source": [
        "import nltk\n",
        "#nltk.download('punkt')\n",
        "from tqdm import tqdm\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence)))\n",
        "\n",
        "data_cleaned = data['cleaned'].progress_apply(clean_text)\n",
        "data_words = list(sent_to_words(data_cleaned))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 25914/25914 [00:00<00:00, 58300.66it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgWpAhXV66ek",
        "colab_type": "text"
      },
      "source": [
        "Every comment ends up as a \"cleaned\" list of words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Aq22JcYe8Z4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "1b2c0d21-7049-4bc9-dd25-8d823db01df0"
      },
      "source": [
        "data_words[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['if',\n",
              " 'all',\n",
              " 'the',\n",
              " 'ice',\n",
              " 'melts',\n",
              " 'surely',\n",
              " 'the',\n",
              " 'tilt',\n",
              " 'of',\n",
              " 'the',\n",
              " 'earth',\n",
              " 'will',\n",
              " 'also',\n",
              " 'change',\n",
              " 'because',\n",
              " 'of',\n",
              " 'the',\n",
              " 'weight',\n",
              " 'diffrence',\n",
              " 'at',\n",
              " 'both',\n",
              " 'poles',\n",
              " 'and',\n",
              " 'would',\n",
              " 'this',\n",
              " 'affect',\n",
              " 'the',\n",
              " 'land',\n",
              " 'mass',\n",
              " 'to',\n",
              " 'change',\n",
              " 'also']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYi6t-iS6i7N",
        "colab_type": "text"
      },
      "source": [
        "### N-grams\n",
        "\n",
        "An n-gram is a contiguous sequence of items in this case words. A bigram consists of two words, a trigram of three words.\n",
        "\n",
        "The gensim Phrase detection automatically detects common sequences.\n",
        "\n",
        "Important params for these n-grams are min_count and threshold. The higher these params harder it is for words to be combined. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysYg_Fds6p23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100)\n",
        "\n",
        "# Exporting the trained model means faster processing BUT model updates no longer possible.\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRkS1StdmNev",
        "colab_type": "text"
      },
      "source": [
        "### Removing stop words, lemmatization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyMSg5E37vw2",
        "colab_type": "text"
      },
      "source": [
        "> TODO: Use different stop word lists or extend existing list?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uymYVH3X6yid",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e3a341e4-906d-4b80-d478-7192db028197"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(elem)) if word not in stop_words] for elem in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[elem] for elem in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTao_Thf8B4u",
        "colab_type": "text"
      },
      "source": [
        "During lemmatization only nouns, adjectives, verbs, and adverbs are kept."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bwszolf7MCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
        "\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjZEu7CQ7P--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "1baf57ff-bcce-4ab3-e696-6af511841ae5"
      },
      "source": [
        "data_lemmatized[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ice',\n",
              " 'melt',\n",
              " 'surely',\n",
              " 'tilt',\n",
              " 'earth',\n",
              " 'also',\n",
              " 'change',\n",
              " 'weight',\n",
              " 'diffrence',\n",
              " 'pole',\n",
              " 'would',\n",
              " 'affect',\n",
              " 'land',\n",
              " 'mass',\n",
              " 'change',\n",
              " 'also']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhoSaoTT7YHC",
        "colab_type": "text"
      },
      "source": [
        "### LDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSuS5win8JoI",
        "colab_type": "text"
      },
      "source": [
        "The gensim LDA model needs dictionary(id2word) and corpus. The dictionary creates an unique id for all words, the corpus maps the id to the number of occurences in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUe5dLfB7VYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim.corpora as corpora\n",
        "\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "texts = data_lemmatized\n",
        "\n",
        "corpus = [id2word.doc2bow(text) for text in texts]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-EI-B_P7dNK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "26bcfd42-2cca-4866-e2b4-03d30aeb8aaa"
      },
      "source": [
        "corpus[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1),\n",
              " (1, 2),\n",
              " (2, 2),\n",
              " (3, 1),\n",
              " (4, 1),\n",
              " (5, 1),\n",
              " (6, 1),\n",
              " (7, 1),\n",
              " (8, 1),\n",
              " (9, 1),\n",
              " (10, 1),\n",
              " (11, 1),\n",
              " (12, 1),\n",
              " (13, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC9EwbaJ7fzF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d65b4c13-aff1-4b9f-f6db-fade6fef3465"
      },
      "source": [
        "id2word[0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'affect'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E3kY0IL7h-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "3ee1fa98-4b15-4f4a-b63a-6ff9f85018e4"
      },
      "source": [
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('affect', 1),\n",
              "  ('also', 2),\n",
              "  ('change', 2),\n",
              "  ('diffrence', 1),\n",
              "  ('earth', 1),\n",
              "  ('ice', 1),\n",
              "  ('land', 1),\n",
              "  ('mass', 1),\n",
              "  ('melt', 1),\n",
              "  ('pole', 1),\n",
              "  ('surely', 1),\n",
              "  ('tilt', 1),\n",
              "  ('weight', 1),\n",
              "  ('would', 1)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfhDjWII8blz",
        "colab_type": "text"
      },
      "source": [
        "Aside from corpus and dictionary, the model takes the number of topics, chunksize (number of documents to be used in each training chunk increasing chunksize speed up training), and passes (epochs) as input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc1dW7uL8cgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_topics = 10\n",
        "chunksize = 100\n",
        "passes = 10\n",
        "\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=num_topics, \n",
        "                                       random_state=100,\n",
        "                                       chunksize=chunksize,\n",
        "                                       passes=passes,\n",
        "                                       per_word_topics=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua8eyyQa8gCe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "0c03c301-569b-4c08-f71d-c8fadb2c51fd"
      },
      "source": [
        "from pprint import pprint\n",
        "\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.068*\"look\" + 0.066*\"would\" + 0.050*\"bad\" + 0.039*\"flood\" + 0.035*\"happen\" '\n",
            "  '+ 0.034*\"lol\" + 0.033*\"go\" + 0.032*\"think\" + 0.031*\"place\" + 0.026*\"state\"'),\n",
            " (1,\n",
            "  '0.049*\"make\" + 0.038*\"video\" + 0.029*\"area\" + 0.023*\"problem\" + '\n",
            "  '0.020*\"music\" + 0.019*\"care\" + 0.016*\"leave\" + 0.016*\"last\" + '\n",
            "  '0.015*\"survive\" + 0.014*\"right\"'),\n",
            " (2,\n",
            "  '0.055*\"city\" + 0.045*\"get\" + 0.043*\"still\" + 0.037*\"good\" + 0.027*\"big\" + '\n",
            "  '0.022*\"need\" + 0.021*\"give\" + 0.020*\"thing\" + 0.017*\"find\" + '\n",
            "  '0.017*\"canadian\"'),\n",
            " (3,\n",
            "  '0.044*\"say\" + 0.039*\"people\" + 0.033*\"much\" + 0.031*\"many\" + 0.022*\"die\" + '\n",
            "  '0.020*\"life\" + 0.018*\"pretty\" + 0.017*\"want\" + 0.016*\"energy\" + '\n",
            "  '0.016*\"seem\"'),\n",
            " (4,\n",
            "  '0.041*\"know\" + 0.028*\"even\" + 0.027*\"go\" + 0.024*\"time\" + 0.024*\"come\" + '\n",
            "  '0.022*\"think\" + 0.020*\"world\" + 0.018*\"really\" + 0.017*\"move\" + '\n",
            "  '0.017*\"fuck\"'),\n",
            " (5,\n",
            "  '0.122*\"water\" + 0.100*\"ice\" + 0.045*\"melt\" + 0.036*\"would\" + 0.034*\"show\" + '\n",
            "  '0.029*\"land\" + 0.024*\"level\" + 0.021*\"take\" + 0.019*\"ocean\" + '\n",
            "  '0.014*\"world\"'),\n",
            " (6,\n",
            "  '0.083*\"go\" + 0.034*\"lot\" + 0.025*\"oil\" + 0.021*\"least\" + 0.021*\"tell\" + '\n",
            "  '0.020*\"stop\" + 0.019*\"population\" + 0.018*\"comment\" + 0.016*\"completely\" + '\n",
            "  '0.012*\"ca\"'),\n",
            " (7,\n",
            "  '0.070*\"live\" + 0.066*\"people\" + 0.038*\"country\" + 0.021*\"world\" + '\n",
            "  '0.020*\"see\" + 0.018*\"use\" + 0.017*\"fucking\" + 0.016*\"keep\" + 0.015*\"money\" '\n",
            "  '+ 0.013*\"help\"'),\n",
            " (8,\n",
            "  '0.093*\"would\" + 0.078*\"sea\" + 0.064*\"level\" + 0.040*\"rise\" + 0.038*\"year\" + '\n",
            "  '0.024*\"become\" + 0.022*\"man\" + 0.017*\"foot\" + 0.015*\"safe\" + 0.014*\"meter\"'),\n",
            " (9,\n",
            "  '0.044*\"change\" + 0.024*\"high\" + 0.024*\"already\" + 0.023*\"put\" + '\n",
            "  '0.022*\"enough\" + 0.020*\"planet\" + 0.019*\"cause\" + 0.017*\"also\" + '\n",
            "  '0.017*\"great\" + 0.016*\"actually\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06ZFyppK8ruk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "badebe90-1ebb-4a69-8d4a-873ff04d0e0f"
      },
      "source": [
        "from gensim.models import CoherenceModel\n",
        "\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # the lower the better.\n",
        "\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Perplexity:  -8.088845491208266\n",
            "\n",
            "Coherence Score:  0.5015008041333983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y56yvIO8t2-",
        "colab_type": "text"
      },
      "source": [
        "### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkgH1sY98wii",
        "colab_type": "text"
      },
      "source": [
        "Alpha and beta are hyperparameters that affect sparsity of the topics\n",
        "\n",
        "[As seen here.](https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0)\n",
        "\n",
        "**The script runs for about 1:50.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv8gUlwX84vZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
        "    \n",
        "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                           id2word=dictionary,\n",
        "                                           num_topics=k, \n",
        "                                           random_state=100,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha=a,\n",
        "                                           eta=b)\n",
        "    \n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "    \n",
        "    return coherence_model_lda.get_coherence()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJcxaB-w9LHy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "6f88efde-d0c3-47c3-cffc-35a3b990b11e"
      },
      "source": [
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "grid = {}\n",
        "grid['Validation_Set'] = {}\n",
        "\n",
        "# Topics range\n",
        "min_topics = 2\n",
        "max_topics = 11\n",
        "step_size = 1\n",
        "topics_range = range(min_topics, max_topics, step_size)\n",
        "\n",
        "# Alpha parameter\n",
        "alpha = list(np.arange(0.01, 1, 0.3))\n",
        "alpha.append('symmetric')\n",
        "alpha.append('asymmetric')\n",
        "\n",
        "# Beta parameter\n",
        "beta = list(np.arange(0.01, 1, 0.3))\n",
        "beta.append('symmetric')\n",
        "\n",
        "# Validation sets\n",
        "num_of_docs = len(corpus)\n",
        "corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n",
        "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
        "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.75), \n",
        "               corpus]\n",
        "\n",
        "corpus_title = ['100% Corpus']\n",
        "\n",
        "model_results = {'Validation_Set': [],\n",
        "                 'Topics': [],\n",
        "                 'Alpha': [],\n",
        "                 'Beta': [],\n",
        "                 'Coherence': []\n",
        "                }\n",
        "\n",
        "# Can take a long time to run\n",
        "if 1 == 1:\n",
        "    pbar = tqdm.tqdm(total=(len(beta)*len(alpha)*len(topics_range)*len(corpus_title)))\n",
        "    \n",
        "    # iterate through validation corpuses\n",
        "    for i in range(len(corpus_sets)):\n",
        "        # iterate through number of topics\n",
        "        for k in topics_range:\n",
        "            # iterate through alpha values\n",
        "            for a in alpha:\n",
        "                # iterare through beta values\n",
        "                for b in beta:\n",
        "                    # get the coherence score for the given parameters\n",
        "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
        "                                                  k=k, a=a, b=b)\n",
        "                    # Save the model results\n",
        "                    model_results['Validation_Set'].append(corpus_title[i])\n",
        "                    model_results['Topics'].append(k)\n",
        "                    model_results['Alpha'].append(a)\n",
        "                    model_results['Beta'].append(b)\n",
        "                    model_results['Coherence'].append(cv)\n",
        "                    \n",
        "                    pbar.update(1)\n",
        "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
        "    pbar.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/270 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
            "  diff = np.log(self.expElogbeta)\n",
            " 57%|█████▋    | 154/270 [4:07:30<3:17:53, 102.36s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee1hc2up9Udq",
        "colab_type": "text"
      },
      "source": [
        "### Analyzing results of hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHIZ0WmF9nLJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19e8e805-4612-442f-9331-7973f9258d24"
      },
      "source": [
        "path = \"lda_tuning_results.csv\"\n",
        "lda_results = pd.read_csv(path, sep=\",\", encoding='utf-8')\n",
        "\n",
        "list(lda_results.columns)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Validation_Set', 'Topics', 'Alpha', 'Beta', 'Coherence']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmtU_avKTMA8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "314d6fd7-5cfe-462f-8da8-76da1d5df908"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "coherence = lda_results.loc[np.logical_and(lda_results.Alpha == \"0.01\", lda_results.Beta == \"0.01\")]['Coherence']\n",
        "topics = lda_results.loc[np.logical_and(lda_results.Alpha == \"0.01\", lda_results.Beta == \"0.01\")]['Topics']\n",
        "\n",
        "plt.plot(topics, coherence, linestyle='-', marker='o')\n",
        "plt.ylabel('Coherence')\n",
        "plt.xlabel('Topics')\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNkMN-5sTPiR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "outputId": "1df1e1d2-30b0-4508-c2d4-9ebc55ce8b7f"
      },
      "source": [
        "lda_results.loc[lda_results.Topics == 8][['Topics', 'Alpha', 'Beta', 'Coherence']]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topics</th>\n",
              "      <th>Alpha</th>\n",
              "      <th>Beta</th>\n",
              "      <th>Coherence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>8</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.629238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>8</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.525422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>8</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.594439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>8</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.550440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>8</td>\n",
              "      <td>0.01</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.591427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>8</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.532120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>8</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.518596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>8</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.515139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>8</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.505914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>8</td>\n",
              "      <td>0.31</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.545217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>8</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.584100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>8</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.569584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>8</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.519875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>8</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.499285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>8</td>\n",
              "      <td>0.61</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.564419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>8</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.600478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>8</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.578524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>8</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.552414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>8</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.499494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>8</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.586429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>8</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.598922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>8</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.551732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>8</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.538215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>8</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.558673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>8</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.555804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>8</td>\n",
              "      <td>asymmetric</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.621256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>8</td>\n",
              "      <td>asymmetric</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.522859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>8</td>\n",
              "      <td>asymmetric</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.632890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>8</td>\n",
              "      <td>asymmetric</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.616448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>8</td>\n",
              "      <td>asymmetric</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.596302</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Topics               Alpha                Beta  Coherence\n",
              "180       8                0.01                0.01   0.629238\n",
              "181       8                0.01                0.31   0.525422\n",
              "182       8                0.01                0.61   0.594439\n",
              "183       8                0.01  0.9099999999999999   0.550440\n",
              "184       8                0.01           symmetric   0.591427\n",
              "185       8                0.31                0.01   0.532120\n",
              "186       8                0.31                0.31   0.518596\n",
              "187       8                0.31                0.61   0.515139\n",
              "188       8                0.31  0.9099999999999999   0.505914\n",
              "189       8                0.31           symmetric   0.545217\n",
              "190       8                0.61                0.01   0.584100\n",
              "191       8                0.61                0.31   0.569584\n",
              "192       8                0.61                0.61   0.519875\n",
              "193       8                0.61  0.9099999999999999   0.499285\n",
              "194       8                0.61           symmetric   0.564419\n",
              "195       8  0.9099999999999999                0.01   0.600478\n",
              "196       8  0.9099999999999999                0.31   0.578524\n",
              "197       8  0.9099999999999999                0.61   0.552414\n",
              "198       8  0.9099999999999999  0.9099999999999999   0.499494\n",
              "199       8  0.9099999999999999           symmetric   0.586429\n",
              "200       8           symmetric                0.01   0.598922\n",
              "201       8           symmetric                0.31   0.551732\n",
              "202       8           symmetric                0.61   0.538215\n",
              "203       8           symmetric  0.9099999999999999   0.558673\n",
              "204       8           symmetric           symmetric   0.555804\n",
              "205       8          asymmetric                0.01   0.621256\n",
              "206       8          asymmetric                0.31   0.522859\n",
              "207       8          asymmetric                0.61   0.632890\n",
              "208       8          asymmetric  0.9099999999999999   0.616448\n",
              "209       8          asymmetric           symmetric   0.596302"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPjtRRu6TYcG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1c78962d-fd0b-4f22-c83e-c255b7ffff07"
      },
      "source": [
        "lda_results.loc[lda_results['Coherence'].idxmax()]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Validation_Set    100% Corpus\n",
              "Topics                      3\n",
              "Alpha              asymmetric\n",
              "Beta                     0.31\n",
              "Coherence            0.705983\n",
              "Name: 56, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4z4huEnTbCn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0bec9f54-cb05-448c-b783-e232b3a82755"
      },
      "source": [
        "tuned_lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=4, \n",
        "                                           random_state=100,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha=\"asymmetric\",\n",
        "                                           eta=0.01)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
            "  diff = np.log(self.expElogbeta)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSJSrsdiTfC4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "87ade975-bfbc-4f37-e044-4567c342ff1a"
      },
      "source": [
        "from pprint import pprint\n",
        "\n",
        "pprint(tuned_lda_model.print_topics())\n",
        "doc_tuned_lda = tuned_lda_model[corpus]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.049*\"go\" + 0.043*\"would\" + 0.023*\"think\" + 0.023*\"people\" + 0.023*\"world\" '\n",
            "  '+ 0.022*\"get\" + 0.022*\"know\" + 0.020*\"live\" + 0.019*\"look\" + '\n",
            "  '0.019*\"happen\"'),\n",
            " (1,\n",
            "  '0.071*\"make\" + 0.046*\"take\" + 0.031*\"lot\" + 0.029*\"right\" + 0.026*\"use\" + '\n",
            "  '0.026*\"put\" + 0.024*\"area\" + 0.024*\"already\" + 0.024*\"care\" + 0.022*\"let\"'),\n",
            " (2,\n",
            "  '0.134*\"water\" + 0.108*\"ice\" + 0.076*\"level\" + 0.062*\"sea\" + 0.048*\"melt\" + '\n",
            "  '0.048*\"would\" + 0.046*\"rise\" + 0.039*\"land\" + 0.026*\"ocean\" + 0.020*\"high\"'),\n",
            " (3,\n",
            "  '0.072*\"say\" + 0.052*\"year\" + 0.034*\"planet\" + 0.029*\"science\" + '\n",
            "  '0.027*\"time\" + 0.027*\"become\" + 0.025*\"earth\" + 0.024*\"man\" + 0.023*\"come\" '\n",
            "  '+ 0.022*\"give\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Juabu-awTpN7",
        "colab_type": "text"
      },
      "source": [
        "### Visual representation\n",
        "\n",
        "Each blue circle represents a topic. The larger the bubble, the more prevalent the topic.\n",
        "\n",
        "Relatively big, non-overlapping bubbles scattered throughout the chart are desirable.\n",
        "\n",
        "By decreasing the value of lamda, more weight is put on the ratio of frequency given the topic to overall frequency of the word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cRGz_MdT5Pb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "534cacf4-5a80-4403-d162-e478fa3afab9"
      },
      "source": [
        "!pip3 install pyLDAvis"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.34.2)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.0.5)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.15.1)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.11.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.7.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Collecting funcy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/4b/6ffa76544e46614123de31574ad95758c421aae391a1764921b8a81e1eae/funcy-1.14.tar.gz (548kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 15.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (47.3.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (19.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.12.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.8.2)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (8.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (0.7.1)\n",
            "Building wheels for collected packages: pyLDAvis, funcy\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97711 sha256=eb27fbf36e0a4e7d93a9cd122090ce6823e49304196c236ea1a354896cc2ca10\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "  Building wheel for funcy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for funcy: filename=funcy-1.14-py2.py3-none-any.whl size=32042 sha256=3ea99ab44456d452c2be0cfc25dae840161f903927c3f4d85e521603c194fb15\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/5a/d8/1d875df03deae6f178dfdf70238cca33f948ef8a6f5209f2eb\n",
            "Successfully built pyLDAvis funcy\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-1.14 pyLDAvis-2.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US7ORk4aTzRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "outputId": "09fa77ba-5104-400c-efe3-7c24ce6910e3"
      },
      "source": [
        "import pyLDAvis.gensim\n",
        "import pickle \n",
        "import pyLDAvis\n",
        "\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "LDAvis_prepared = pyLDAvis.gensim.prepare(tuned_lda_model, corpus, id2word)\n",
        "\n",
        "LDAvis_prepared"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1221404183235046088877485722\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1221404183235046088877485722_data = {\"mdsDat\": {\"x\": [-0.214322198419539, -0.26782286624531526, 0.3156101545320482, 0.16653491013280583], \"y\": [0.08108448907472655, -0.1580134250314768, -0.25324631215101073, 0.330175248107761], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [46.397544860839844, 21.01437759399414, 17.177122116088867, 15.4109525680542]}, \"tinfo\": {\"Term\": [\"water\", \"ice\", \"level\", \"make\", \"say\", \"sea\", \"go\", \"melt\", \"rise\", \"would\", \"year\", \"take\", \"land\", \"planet\", \"lot\", \"right\", \"ocean\", \"time\", \"science\", \"think\", \"people\", \"world\", \"use\", \"get\", \"know\", \"put\", \"become\", \"area\", \"already\", \"come\", \"go\", \"think\", \"world\", \"get\", \"know\", \"live\", \"look\", \"happen\", \"see\", \"country\", \"city\", \"video\", \"show\", \"bad\", \"still\", \"good\", \"flood\", \"really\", \"lol\", \"move\", \"fuck\", \"want\", \"need\", \"big\", \"could\", \"well\", \"state\", \"part\", \"maybe\", \"little\", \"even\", \"would\", \"people\", \"much\", \"thing\", \"place\", \"water\", \"ice\", \"level\", \"sea\", \"melt\", \"rise\", \"land\", \"ocean\", \"high\", \"human\", \"foot\", \"build\", \"whole\", \"glass\", \"matter\", \"surface\", \"example\", \"low\", \"sit\", \"top\", \"increase\", \"pole\", \"glacier\", \"coastal\", \"fill\", \"river\", \"fresh\", \"plant\", \"side\", \"cube\", \"would\", \"change\", \"earth\", \"temperature\", \"much\", \"make\", \"take\", \"lot\", \"right\", \"use\", \"put\", \"area\", \"already\", \"care\", \"let\", \"actually\", \"cause\", \"stupid\", \"stop\", \"comment\", \"canadian\", \"keep\", \"less\", \"true\", \"thank\", \"leave\", \"last\", \"money\", \"rate\", \"guy\", \"question\", \"source\", \"scientific\", \"start\", \"freeze\", \"many\", \"change\", \"people\", \"year\", \"say\", \"planet\", \"science\", \"become\", \"man\", \"give\", \"back\", \"climate\", \"age\", \"call\", \"watch\", \"first\", \"real\", \"end\", \"believe\", \"help\", \"basically\", \"old\", \"turn\", \"always\", \"cap\", \"play\", \"stay\", \"close\", \"cool\", \"lie\", \"nice\", \"bring\", \"island\", \"next\", \"year\", \"time\", \"come\", \"earth\", \"fact\", \"change\", \"never\"], \"Freq\": [5045.0, 4054.0, 2856.0, 2191.0, 1994.0, 2320.0, 4080.0, 1811.0, 1744.0, 5402.0, 2023.0, 1412.0, 1470.0, 934.0, 936.0, 882.0, 976.0, 1232.0, 793.0, 1928.0, 2552.0, 1873.0, 805.0, 1836.0, 1826.0, 791.0, 740.0, 747.0, 746.0, 1204.0, 4080.483154296875, 1928.3427734375, 1873.4625244140625, 1836.8218994140625, 1826.1475830078125, 1638.653564453125, 1560.9564208984375, 1547.7445068359375, 1461.1844482421875, 1445.5093994140625, 1388.96044921875, 1316.44287109375, 1257.010986328125, 1167.792236328125, 1052.8441162109375, 889.748291015625, 873.0531005859375, 833.164794921875, 801.5630493164062, 767.0376586914062, 750.2550659179688, 739.5517578125, 721.4754638671875, 687.6347045898438, 677.8204956054688, 661.8359985351562, 600.9163818359375, 567.645751953125, 534.7540283203125, 531.7664184570312, 1351.0992431640625, 3594.2060546875, 1876.5118408203125, 1096.31884765625, 854.9848022460938, 689.5187377929688, 5044.99365234375, 4054.152099609375, 2856.791748046875, 2320.157470703125, 1811.62109375, 1744.1005859375, 1470.740478515625, 976.4658203125, 769.1975708007812, 693.9830322265625, 476.55059814453125, 400.1036071777344, 377.7874755859375, 362.79705810546875, 335.3841857910156, 331.8191223144531, 326.52911376953125, 316.7562561035156, 276.4915771484375, 261.3781433105469, 260.4261779785156, 255.8404541015625, 253.76535034179688, 242.84686279296875, 241.49642944335938, 240.5604248046875, 233.83651733398438, 230.5375213623047, 229.2737274169922, 225.41070556640625, 1808.00390625, 384.0887756347656, 364.71270751953125, 263.3959655761719, 305.3024597167969, 2191.1552734375, 1412.590576171875, 936.6483764648438, 882.8888549804688, 805.7127685546875, 791.593017578125, 747.8040771484375, 746.165283203125, 723.5330200195312, 684.5888061523438, 668.8701782226562, 600.5543823242188, 599.5921630859375, 561.286376953125, 508.36004638671875, 500.7195739746094, 478.2244567871094, 462.55474853515625, 454.8573303222656, 446.2518005371094, 417.8139343261719, 404.08306884765625, 394.5924072265625, 360.53070068359375, 306.1376953125, 300.0382385253906, 287.9457092285156, 277.15509033203125, 275.07855224609375, 256.8888854980469, 614.4502563476562, 663.9534912109375, 675.5711669921875, 583.0692138671875, 1994.44140625, 934.0665893554688, 793.3002319335938, 740.3629150390625, 656.4766845703125, 615.825927734375, 611.961181640625, 516.7877807617188, 467.2532958984375, 427.2046203613281, 426.7506408691406, 397.3827819824219, 386.64898681640625, 382.71722412109375, 380.8902282714844, 360.9783935546875, 339.9051208496094, 334.4097595214844, 325.52947998046875, 315.2369384765625, 297.10394287109375, 292.1632995605469, 291.0572509765625, 290.7314147949219, 286.2425537109375, 286.12420654296875, 280.5197448730469, 262.63592529296875, 248.36227416992188, 247.20401000976562, 1440.5750732421875, 752.7745361328125, 638.4768676757812, 691.2077026367188, 395.7939453125, 424.68585205078125, 314.62548828125], \"Total\": [5045.0, 4054.0, 2856.0, 2191.0, 1994.0, 2320.0, 4080.0, 1811.0, 1744.0, 5402.0, 2023.0, 1412.0, 1470.0, 934.0, 936.0, 882.0, 976.0, 1232.0, 793.0, 1928.0, 2552.0, 1873.0, 805.0, 1836.0, 1826.0, 791.0, 740.0, 747.0, 746.0, 1204.0, 4080.527587890625, 1928.3873291015625, 1873.507080078125, 1836.866455078125, 1826.192138671875, 1638.6981201171875, 1561.0009765625, 1547.7890625, 1461.22900390625, 1445.553955078125, 1389.0050048828125, 1316.4874267578125, 1257.0555419921875, 1167.8367919921875, 1052.888671875, 889.7927856445312, 873.0975952148438, 833.2092895507812, 801.6075439453125, 767.0821533203125, 750.299560546875, 739.5962524414062, 721.5199584960938, 687.67919921875, 677.864990234375, 661.8804931640625, 600.9608764648438, 567.6902465820312, 534.7985229492188, 531.8111572265625, 1539.002197265625, 5402.240234375, 2552.112548828125, 1401.6513671875, 1091.6253662109375, 741.1685791015625, 5045.03662109375, 4054.19482421875, 2856.83447265625, 2320.2001953125, 1811.663818359375, 1744.143310546875, 1470.783203125, 976.508544921875, 769.2402954101562, 694.0257568359375, 476.59326171875, 400.1462707519531, 377.83013916015625, 362.8397216796875, 335.4268493652344, 331.8617858886719, 326.57177734375, 316.7989196777344, 276.53424072265625, 261.4208068847656, 260.4688415527344, 255.8831329345703, 253.8080291748047, 242.88954162597656, 241.5391082763672, 240.6031036376953, 233.8791961669922, 230.5802001953125, 229.31640625, 225.45338439941406, 5402.240234375, 1472.74072265625, 1667.71435546875, 461.80010986328125, 1401.6513671875, 2191.197265625, 1412.6326904296875, 936.6905517578125, 882.9310302734375, 805.7549438476562, 791.6351928710938, 747.8462524414062, 746.2074584960938, 723.5751953125, 684.6309814453125, 668.912353515625, 600.5965576171875, 599.6343383789062, 561.3285522460938, 508.40216064453125, 500.7616882324219, 478.2665710449219, 462.59686279296875, 454.8994445800781, 446.2939147949219, 417.8560485839844, 404.12518310546875, 394.634521484375, 360.57281494140625, 306.1798095703125, 300.0803527832031, 287.9878234863281, 277.19720458984375, 275.12066650390625, 256.9309997558594, 844.5452270507812, 1472.74072265625, 2552.112548828125, 2023.67138671875, 1994.4835205078125, 934.1087646484375, 793.3424072265625, 740.4050903320312, 656.5188598632812, 615.8681030273438, 612.0033569335938, 516.8299560546875, 467.29547119140625, 427.2467956542969, 426.7928161621094, 397.4249572753906, 386.691162109375, 382.7593994140625, 380.9324035644531, 361.02056884765625, 339.9472961425781, 334.4519348144531, 325.5716552734375, 315.27911376953125, 297.1461181640625, 292.2054748535156, 291.09942626953125, 290.7735900878906, 286.28472900390625, 286.1663818359375, 280.5619201660156, 262.6781005859375, 248.40443420410156, 247.2461700439453, 2023.67138671875, 1232.104736328125, 1204.0467529296875, 1667.71435546875, 646.347412109375, 1472.74072265625, 586.7277221679688], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.0114998817443848, -3.760999917984009, -3.789900064468384, -3.8096001148223877, -3.815500020980835, -3.923799991607666, -3.972399950027466, -3.9809000492095947, -4.038400173187256, -4.049200057983398, -4.089099884033203, -4.1427001953125, -4.188899993896484, -4.262599945068359, -4.366199970245361, -4.5345001220703125, -4.553400039672852, -4.600200176239014, -4.638899803161621, -4.6828999519348145, -4.704999923706055, -4.719399929046631, -4.744100093841553, -4.792200088500977, -4.80649995803833, -4.830399990081787, -4.927000045776367, -4.98390007019043, -5.043600082397461, -5.049200057983398, -4.116799831390381, -3.138400077819824, -3.788300037384033, -4.325699806213379, -4.5742998123168945, -4.789400100708008, -2.007200002670288, -2.2258999347686768, -2.575900077819824, -2.7839999198913574, -3.031399965286255, -3.0694000720977783, -3.2399001121520996, -3.6494998931884766, -3.888000011444092, -3.9909000396728516, -4.366799831390381, -4.5416998863220215, -4.599100112915039, -4.639500141143799, -4.718100070953369, -4.728799819946289, -4.744900226593018, -4.775300025939941, -4.911200046539307, -4.967400074005127, -4.971099853515625, -4.988800048828125, -4.997000217437744, -5.040999889373779, -5.046500205993652, -5.0503997802734375, -5.078800201416016, -5.0929999351501465, -5.098499774932861, -5.115499973297119, -3.033400058746338, -4.582499980926514, -4.634300231933594, -4.959700107574463, -4.812099933624268, -2.6396000385284424, -3.0785999298095703, -3.489500045776367, -3.5485999584198, -3.640000104904175, -3.6577000617980957, -3.714600086212158, -3.7167999744415283, -3.7476000785827637, -3.8029000759124756, -3.826200008392334, -3.9339001178741455, -3.935499906539917, -4.001500129699707, -4.100599765777588, -4.115699768066406, -4.1616997718811035, -4.195000171661377, -4.2118000984191895, -4.230899810791016, -4.2967000007629395, -4.330100059509277, -4.353899955749512, -4.444200038909912, -4.607699871063232, -4.627900123596191, -4.669000148773193, -4.707200050354004, -4.714700222015381, -4.783100128173828, -3.9110000133514404, -3.8336000442504883, -3.816200017929077, -3.9635000228881836, -2.6250998973846436, -3.383699893951416, -3.547100067138672, -3.6161000728607178, -3.7363998889923096, -3.800299882888794, -3.8066000938415527, -3.975600004196167, -4.076399803161621, -4.165999889373779, -4.167099952697754, -4.238399982452393, -4.265699863433838, -4.276000022888184, -4.280799865722656, -4.334400177001953, -4.394599914550781, -4.410900115966797, -4.43779993057251, -4.469900131225586, -4.529200077056885, -4.546000003814697, -4.549699783325195, -4.550899982452393, -4.566400051116943, -4.566800117492676, -4.586599826812744, -4.652500152587891, -4.708399772644043, -4.7129998207092285, -2.950500011444092, -3.5994999408721924, -3.76419997215271, -3.684799909591675, -4.242400169372559, -4.171899795532227, -4.47189998626709], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.7678999900817871, 0.767799973487854, 0.767799973487854, 0.767799973487854, 0.767799973487854, 0.6377000212669373, 0.36039999127388, 0.4603999853134155, 0.5221999883651733, 0.5235999822616577, 0.6956999897956848, 1.559999942779541, 1.559999942779541, 1.5599000453948975, 1.5599000453948975, 1.5599000453948975, 1.5599000453948975, 1.5599000453948975, 1.5599000453948975, 1.5599000453948975, 1.5599000453948975, 1.5599000453948975, 1.5599000453948975, 1.5599000453948975, 1.5598000288009644, 1.5598000288009644, 1.5598000288009644, 1.5598000288009644, 1.5598000288009644, 1.5598000288009644, 1.5598000288009644, 1.5598000288009644, 1.5598000288009644, 1.5598000288009644, 1.5598000288009644, 1.5598000288009644, 1.5598000288009644, 1.5598000288009644, 1.5598000288009644, 1.5598000288009644, 1.5598000288009644, 0.46540001034736633, 0.2160000056028366, 0.039900001138448715, 0.9984999895095825, 0.03590000048279762, 1.7616000175476074, 1.7616000175476074, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7615000009536743, 1.7613999843597412, 1.7613999843597412, 1.7613999843597412, 1.7613999843597412, 1.44350004196167, 0.964900016784668, 0.4325000047683716, 0.5171999931335449, 1.8701000213623047, 1.8700000047683716, 1.8700000047683716, 1.8700000047683716, 1.8700000047683716, 1.8700000047683716, 1.8700000047683716, 1.8700000047683716, 1.8700000047683716, 1.8700000047683716, 1.8700000047683716, 1.8700000047683716, 1.8700000047683716, 1.8700000047683716, 1.8700000047683716, 1.8700000047683716, 1.8700000047683716, 1.8700000047683716, 1.8700000047683716, 1.8700000047683716, 1.8698999881744385, 1.8698999881744385, 1.8698999881744385, 1.8698999881744385, 1.8698999881744385, 1.8698999881744385, 1.8698999881744385, 1.8698999881744385, 1.8698999881744385, 1.8698999881744385, 1.5302000045776367, 1.3774000406265259, 1.235700011253357, 0.989300012588501, 1.3796000480651855, 0.6266000270843506, 1.246899962425232]}, \"token.table\": {\"Topic\": [3, 4, 3, 4, 3, 4, 1, 4, 4, 4, 1, 4, 2, 4, 3, 4, 3, 3, 2, 3, 4, 1, 4, 4, 2, 1, 4, 3, 4, 1, 1, 2, 1, 2, 4, 4, 1, 2, 2, 3, 4, 2, 4, 1, 2, 3, 2, 1, 1, 4, 2, 2, 1, 1, 3, 1, 4, 2, 2, 2, 2, 4, 3, 1, 2, 3, 3, 3, 3, 2, 4, 1, 1, 1, 1, 3, 2, 3, 4, 3, 4, 2, 1, 2, 3, 1, 1, 2, 1, 1, 4, 4, 4, 2, 4, 1, 1, 3, 1, 2, 4, 2, 4, 2, 3, 3, 3, 4, 1, 3, 2, 2, 4, 4, 3, 2, 1, 1, 2, 2, 3, 3, 1, 4, 1, 3, 3, 2, 3, 2, 4, 3, 1, 4, 1, 1, 3, 4, 2, 3, 4, 3, 1, 1, 4, 2, 1, 2, 1, 1, 2, 3, 4], \"Freq\": [1.0001310110092163, 0.9993677139282227, 0.9997220039367676, 0.9991146922111511, 1.000205636024475, 0.9999945163726807, 1.0001397132873535, 1.0001550912857056, 0.9994528889656067, 1.0001775026321411, 1.0004664659500122, 1.001225471496582, 0.9996344447135925, 0.9994223713874817, 1.0004758834838867, 0.999508261680603, 1.0005871057510376, 1.0006717443466187, 0.2607383728027344, 0.45086008310317993, 0.2885776162147522, 0.9999964237213135, 1.0003290176391602, 1.0007786750793457, 1.0004547834396362, 0.4700814187526703, 0.5298797488212585, 0.9992089867591858, 0.9990054368972778, 1.0001991987228394, 1.0003085136413574, 0.9979889988899231, 0.3669693171977997, 0.2188624143600464, 0.414339542388916, 1.0006285905838013, 0.8778414726257324, 0.12215706706047058, 1.0013113021850586, 0.38833606243133545, 0.6126735806465149, 0.9977680444717407, 0.9989307522773743, 0.9998882412910461, 1.000853419303894, 1.000268578529358, 1.0005165338516235, 0.9996007680892944, 1.000072717666626, 1.0002142190933228, 1.0007563829421997, 1.0004417896270752, 0.9998707175254822, 1.0002329349517822, 0.9994127154350281, 1.0001362562179565, 0.9999430179595947, 0.9996876120567322, 0.9999628663063049, 0.999951958656311, 0.998199999332428, 0.9983718991279602, 0.9994426369667053, 0.9998947978019714, 1.0001474618911743, 0.9996902346611023, 1.0003445148468018, 1.0008714199066162, 1.000538945198059, 1.0000579357147217, 0.9994185566902161, 1.0003551244735718, 1.000184178352356, 1.000489592552185, 0.9999994039535522, 1.0003303289413452, 1.0006346702575684, 0.9999099969863892, 0.9992097020149231, 0.7270184755325317, 0.2723359167575836, 0.9987274408340454, 1.0003767013549805, 1.0001856088638306, 1.00092613697052, 0.9998928904533386, 0.7819347977638245, 0.217600479722023, 0.9992793798446655, 0.4635881185531616, 0.5368759632110596, 0.9990043640136719, 1.0015614032745361, 0.9994792342185974, 0.9986487030982971, 1.000545620918274, 0.7354691028594971, 0.26487860083580017, 0.9309622645378113, 0.07015947997570038, 0.9998835921287537, 1.0018205642700195, 0.9992967844009399, 1.000456690788269, 1.0004608631134033, 0.999732255935669, 1.0011847019195557, 1.0007987022399902, 0.9997488260269165, 1.0000780820846558, 0.9999178051948547, 1.0016496181488037, 0.9997575879096985, 0.9995684027671814, 0.9992885589599609, 0.9999136924743652, 0.9998432993888855, 0.9999558329582214, 0.9986202120780945, 0.99806809425354, 1.0000423192977905, 0.9995614290237427, 1.0000650882720947, 0.999658465385437, 1.0001057386398315, 0.9994146823883057, 1.0006097555160522, 1.0004165172576904, 1.0002599954605103, 0.5695104598999023, 0.4287569224834442, 0.9993414282798767, 0.7832357287406921, 0.21710744500160217, 0.9997991323471069, 0.3879540264606476, 0.0016232386697083712, 0.6111493706703186, 0.9983903169631958, 1.0002210140228271, 1.001315712928772, 1.000304102897644, 0.9996297359466553, 1.000545859336853, 1.0004854202270508, 0.9999927282333374, 1.0001806020736694, 1.000449538230896, 0.999729335308075, 0.6652795672416687, 0.33467596769332886, 0.2880902588367462, 0.7120721340179443], \"Term\": [\"actually\", \"age\", \"already\", \"always\", \"area\", \"back\", \"bad\", \"basically\", \"become\", \"believe\", \"big\", \"bring\", \"build\", \"call\", \"canadian\", \"cap\", \"care\", \"cause\", \"change\", \"change\", \"change\", \"city\", \"climate\", \"close\", \"coastal\", \"come\", \"come\", \"comment\", \"cool\", \"could\", \"country\", \"cube\", \"earth\", \"earth\", \"earth\", \"end\", \"even\", \"even\", \"example\", \"fact\", \"fact\", \"fill\", \"first\", \"flood\", \"foot\", \"freeze\", \"fresh\", \"fuck\", \"get\", \"give\", \"glacier\", \"glass\", \"go\", \"good\", \"guy\", \"happen\", \"help\", \"high\", \"human\", \"ice\", \"increase\", \"island\", \"keep\", \"know\", \"land\", \"last\", \"leave\", \"less\", \"let\", \"level\", \"lie\", \"little\", \"live\", \"lol\", \"look\", \"lot\", \"low\", \"make\", \"man\", \"many\", \"many\", \"matter\", \"maybe\", \"melt\", \"money\", \"move\", \"much\", \"much\", \"need\", \"never\", \"never\", \"next\", \"nice\", \"ocean\", \"old\", \"part\", \"people\", \"people\", \"place\", \"place\", \"planet\", \"plant\", \"play\", \"pole\", \"put\", \"question\", \"rate\", \"real\", \"really\", \"right\", \"rise\", \"river\", \"say\", \"science\", \"scientific\", \"sea\", \"see\", \"show\", \"side\", \"sit\", \"source\", \"start\", \"state\", \"stay\", \"still\", \"stop\", \"stupid\", \"surface\", \"take\", \"temperature\", \"temperature\", \"thank\", \"thing\", \"thing\", \"think\", \"time\", \"time\", \"time\", \"top\", \"true\", \"turn\", \"use\", \"video\", \"want\", \"watch\", \"water\", \"well\", \"whole\", \"world\", \"would\", \"would\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 3, 2, 4]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1221404183235046088877485722\", ldavis_el1221404183235046088877485722_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1221404183235046088877485722\", ldavis_el1221404183235046088877485722_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1221404183235046088877485722\", ldavis_el1221404183235046088877485722_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "0     -0.214322  0.081084       1        1  46.397545\n",
              "2     -0.267823 -0.158013       2        1  21.014378\n",
              "1      0.315610 -0.253246       3        1  17.177122\n",
              "3      0.166535  0.330175       4        1  15.410953, topic_info=       Term         Freq        Total Category  logprob  loglift\n",
              "51    water  5045.000000  5045.000000  Default  30.0000  30.0000\n",
              "5       ice  4054.000000  4054.000000  Default  29.0000  29.0000\n",
              "73    level  2856.000000  2856.000000  Default  28.0000  28.0000\n",
              "42     make  2191.000000  2191.000000  Default  27.0000  27.0000\n",
              "91      say  1994.000000  1994.000000  Default  26.0000  26.0000\n",
              "..      ...          ...          ...      ...      ...      ...\n",
              "191    come   638.476868  1204.046753   Topic4  -3.7642   1.2357\n",
              "4     earth   691.207703  1667.714355   Topic4  -3.6848   0.9893\n",
              "280    fact   395.793945   646.347412   Topic4  -4.2424   1.3796\n",
              "2    change   424.685852  1472.740723   Topic4  -4.1719   0.6266\n",
              "251   never   314.625488   586.727722   Topic4  -4.4719   1.2469\n",
              "\n",
              "[172 rows x 6 columns], token_table=      Topic      Freq      Term\n",
              "term                           \n",
              "81        3  1.000131  actually\n",
              "189       4  0.999368       age\n",
              "318       3  0.999722   already\n",
              "550       4  0.999115    always\n",
              "97        3  1.000206      area\n",
              "...     ...       ...       ...\n",
              "244       1  0.999729     world\n",
              "13        1  0.665280     would\n",
              "13        2  0.334676     would\n",
              "55        3  0.288090      year\n",
              "55        4  0.712072      year\n",
              "\n",
              "[153 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 3, 2, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0WEF6-tU839",
        "colab_type": "text"
      },
      "source": [
        "#### Most representative topic for each comment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRp0zDL6UTTB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcce7b12-9a17-4f97-dd91-612ab57163be"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def show_comment_topics(ldamodel, corpus, documents):\n",
        "    topics_data = pd.DataFrame()\n",
        "\n",
        "    #iterate over model corpus\n",
        "    for index, row in tqdm(enumerate(ldamodel[corpus])):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        \n",
        "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
        "        for i, (topic_num, prop_topic) in enumerate(row):\n",
        "            if i == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                topics_data = topics_data.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    topics_data.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "    # Append original comment at the end\n",
        "    contents = pd.Series(documents['text'])\n",
        "    topics_data = pd.concat([topics_data, contents], axis=1)\n",
        "    return(topics_data)\n",
        "\n",
        "data_topic_keywords = show_comment_topics(tuned_lda_model, corpus, data)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25914it [02:00, 214.54it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmQX-3LAU4qc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "f0e1e6ae-e1cc-42a6-c002-5a806d6741e7"
      },
      "source": [
        "data_dominant_topic = data_topic_keywords.reset_index()\n",
        "data_dominant_topic.columns = ['Comment Nr', 'Dominant Topic', '% of Topic in Comment', 'Keywords', 'Comment']\n",
        "\n",
        "data_dominant_topic.loc[:, 'Dominant Topic':'Comment'].head(20)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dominant Topic</th>\n",
              "      <th>% of Topic in Comment</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.4766</td>\n",
              "      <td>water, ice, level, sea, melt, would, rise, lan...</td>\n",
              "      <td>If all the ice melts surely the tilt of the ea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9128</td>\n",
              "      <td>go, would, think, people, world, get, know, li...</td>\n",
              "      <td>The scariest part of the video is the music......</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6948</td>\n",
              "      <td>go, would, think, people, world, get, know, li...</td>\n",
              "      <td>New Zealand be like...\"are we good?\" 🤷‍♂️\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8779</td>\n",
              "      <td>go, would, think, people, world, get, know, li...</td>\n",
              "      <td>Step #1: Taxes... Step #2: ???... Step #3: Uto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4632</td>\n",
              "      <td>go, would, think, people, world, get, know, li...</td>\n",
              "      <td>Strange how Hudson's Bay stayed the same size....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3896</td>\n",
              "      <td>go, would, think, people, world, get, know, li...</td>\n",
              "      <td>Sweet I'll have ocean front property.\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4632</td>\n",
              "      <td>go, would, think, people, world, get, know, li...</td>\n",
              "      <td>Brazil will lost 25% of territory 😂\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5974</td>\n",
              "      <td>go, would, think, people, world, get, know, li...</td>\n",
              "      <td>Lesson learned : dont put your capitol city ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.4046</td>\n",
              "      <td>water, ice, level, sea, melt, would, rise, lan...</td>\n",
              "      <td>If this was an actual concern...at all...then ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4842</td>\n",
              "      <td>go, would, think, people, world, get, know, li...</td>\n",
              "      <td>If I was 100 years old, i'll be the first to d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3896</td>\n",
              "      <td>go, would, think, people, world, get, know, li...</td>\n",
              "      <td>Florida and Delaware: Aight imma head out\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.3778</td>\n",
              "      <td>say, year, planet, science, time, become, eart...</td>\n",
              "      <td>Let's drop some nukes on those ice caps and sp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7956</td>\n",
              "      <td>go, would, think, people, world, get, know, li...</td>\n",
              "      <td>More like what America would look like.\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4132</td>\n",
              "      <td>make, take, lot, right, use, put, area, alread...</td>\n",
              "      <td>So your telling me I'm walking on ice right no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4632</td>\n",
              "      <td>go, would, think, people, world, get, know, li...</td>\n",
              "      <td>Just build lol\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.4747</td>\n",
              "      <td>water, ice, level, sea, melt, would, rise, lan...</td>\n",
              "      <td>you don't really believe this crap do you, the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5960</td>\n",
              "      <td>go, would, think, people, world, get, know, li...</td>\n",
              "      <td>this isn’t funny. doesn’t anybody care about t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.3680</td>\n",
              "      <td>make, take, lot, right, use, put, area, alread...</td>\n",
              "      <td>Are you serious? The earth is going to do its ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6336</td>\n",
              "      <td>make, take, lot, right, use, put, area, alread...</td>\n",
              "      <td>My question is... Does this account for the we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8472</td>\n",
              "      <td>go, would, think, people, world, get, know, li...</td>\n",
              "      <td>Atlantis be like sweet new friends\\n\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Dominant Topic  ...                                            Comment\n",
              "0              2.0  ...  If all the ice melts surely the tilt of the ea...\n",
              "1              0.0  ...  The scariest part of the video is the music......\n",
              "2              0.0  ...      New Zealand be like...\"are we good?\" 🤷‍♂️\\n\\n\n",
              "3              0.0  ...  Step #1: Taxes... Step #2: ???... Step #3: Uto...\n",
              "4              0.0  ...  Strange how Hudson's Bay stayed the same size....\n",
              "5              0.0  ...          Sweet I'll have ocean front property.\\n\\n\n",
              "6              0.0  ...            Brazil will lost 25% of territory 😂\\n\\n\n",
              "7              0.0  ...  Lesson learned : dont put your capitol city ne...\n",
              "8              2.0  ...  If this was an actual concern...at all...then ...\n",
              "9              0.0  ...  If I was 100 years old, i'll be the first to d...\n",
              "10             0.0  ...      Florida and Delaware: Aight imma head out\\n\\n\n",
              "11             3.0  ...  Let's drop some nukes on those ice caps and sp...\n",
              "12             0.0  ...        More like what America would look like.\\n\\n\n",
              "13             1.0  ...  So your telling me I'm walking on ice right no...\n",
              "14             0.0  ...                                 Just build lol\\n\\n\n",
              "15             2.0  ...  you don't really believe this crap do you, the...\n",
              "16             0.0  ...  this isn’t funny. doesn’t anybody care about t...\n",
              "17             1.0  ...  Are you serious? The earth is going to do its ...\n",
              "18             1.0  ...  My question is... Does this account for the we...\n",
              "19             0.0  ...             Atlantis be like sweet new friends\\n\\n\n",
              "\n",
              "[20 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7bp7WZBVEUx",
        "colab_type": "text"
      },
      "source": [
        "#### Most representative comments for each topic\n",
        "\n",
        "Index shows original placement of commment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKs03thyVMl0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7af41ab9-e4c5-478c-d66c-710c89f479bf"
      },
      "source": [
        "top_comments_df = pd.DataFrame()\n",
        "\n",
        "for topic in data_topic_keywords.groupby('Dominant_Topic'):\n",
        "    top_comments_df = pd.concat([top_comments_df, topic[1].sort_values(['Perc_Contribution'], ascending=[0]).head(5)])\n",
        "\n",
        "top_comments_df.columns= ['Dominant Topic', '% of Topic in Comment', 'Keywords', 'Comment']\n",
        "pd.options.display.max_rows\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "top_comments_df"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dominant Topic</th>\n",
              "      <th>% of Topic in Comment</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3535</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9660</td>\n",
              "      <td>go, would, think, people, world, get, know, live, look, happen</td>\n",
              "      <td>There will probably be a billion people living in mumbai, shanghai and beijing\\n(combined) by the time this happens. Looks pretty catastrophic to me. NY is\\nthe finance hub of the world, SF the tech hub of the world... how is this not\\nbad? And all the people living in these gigantic cities? Where are they going\\nto go? No... it's really, really bad!\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9592</td>\n",
              "      <td>go, would, think, people, world, get, know, live, look, happen</td>\n",
              "      <td>So why is waterfront property still cost so much and getting more expensive?\\nYoud think the property would be worthless knowing what we know. Right? Yeah.\\nExactly. Dont worry youth. You'll be fine.\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5837</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9592</td>\n",
              "      <td>go, would, think, people, world, get, know, live, look, happen</td>\n",
              "      <td>From what I guess, most likely not but who knows maybe if we are lucky\\nsomething will happen on Earth andthey might be and maybe things will be more\\nmanageable but no one knows for sure, we can just hope for the best when such\\na time comes.\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20842</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9564</td>\n",
              "      <td>go, would, think, people, world, get, know, live, look, happen</td>\n",
              "      <td>We do something against the rising water though ;D\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24563</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9562</td>\n",
              "      <td>go, would, think, people, world, get, know, live, look, happen</td>\n",
              "      <td>Or Gambia.\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1718</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8942</td>\n",
              "      <td>make, take, lot, right, use, put, area, already, care, let</td>\n",
              "      <td>Baltics have left the chat Crimea can into island Kallinigrad has left the\\nchat Tunisia has left the chat East Italy has left the chat UK can into\\nArchapeligo Delaware has left the Chat Kuwait has left the chat\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1710</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8519</td>\n",
              "      <td>make, take, lot, right, use, put, area, already, care, let</td>\n",
              "      <td>Delaware has left the chat Louisiana has left the chat (i have left the chat)\\nRhode Island has left the chat\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1700</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8519</td>\n",
              "      <td>make, take, lot, right, use, put, area, already, care, let</td>\n",
              "      <td>Florida has left the chat  \\nThe Netherlands has left the chat  \\nBangladesh has left the chat  \\nDenmark has left the chat\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15894</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8519</td>\n",
              "      <td>make, take, lot, right, use, put, area, already, care, let</td>\n",
              "      <td>Good thing I don't live in Florida. Now Miami is now just on an island.\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6265</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8518</td>\n",
              "      <td>make, take, lot, right, use, put, area, already, care, let</td>\n",
              "      <td>you will be one of those sources after a couple more winters and the facts\\nbeat you into humility............\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12485</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.9381</td>\n",
              "      <td>water, ice, level, sea, melt, would, rise, land, ocean, high</td>\n",
              "      <td>Fill a glass with ice cubes, top it off with water, when the ice cubes have\\nmelted the water level will be lower.\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3253</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.9099</td>\n",
              "      <td>water, ice, level, sea, melt, would, rise, land, ocean, high</td>\n",
              "      <td>Melting *SEA* ice does not change sea level. Melting *LAND* ice does.\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14821</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.8994</td>\n",
              "      <td>water, ice, level, sea, melt, would, rise, land, ocean, high</td>\n",
              "      <td>JEFFREY G DELABRE not exactly... the melting of ice into the ocean will alter\\nthe salinity... So much so that most ocean life will suffer due to a drastic\\nchange to their environment...\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23760</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.8994</td>\n",
              "      <td>water, ice, level, sea, melt, would, rise, land, ocean, high</td>\n",
              "      <td>+Lowmomome you have no idea what else follows...\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11930</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.8981</td>\n",
              "      <td>water, ice, level, sea, melt, would, rise, land, ocean, high</td>\n",
              "      <td>Riiiight ... because water flowing off land would not add to the water in the\\noceans.\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10030</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.8582</td>\n",
              "      <td>say, year, planet, science, time, become, earth, man, come, give</td>\n",
              "      <td>Yep, but real climatologists say the earth is in a 176 year cool down.\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19044</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.8312</td>\n",
              "      <td>say, year, planet, science, time, become, earth, man, come, give</td>\n",
              "      <td>Wow is that ever some tangled logic and in any case it's pretty incredible\\nthat there are people who deny the weight of evidence behind climate change .\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2874</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.8312</td>\n",
              "      <td>say, year, planet, science, time, become, earth, man, come, give</td>\n",
              "      <td>SCIENCE INSIDER  \\n  \\n  \\n  \\n  \\nSAYS BUISNESS INSIDER IN THE CORNER  \\n🤔\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16007</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.8247</td>\n",
              "      <td>say, year, planet, science, time, become, earth, man, come, give</td>\n",
              "      <td>Paulo Junior Florida, South Carolina, Denmark and netherlands\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8673</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.7890</td>\n",
              "      <td>say, year, planet, science, time, become, earth, man, come, give</td>\n",
              "      <td>it said business insider but this is science insider\\n\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Dominant Topic  ...                                                                                                                                                                                                                                                                                                                                                               Comment\n",
              "3535              0.0  ...  There will probably be a billion people living in mumbai, shanghai and beijing\\n(combined) by the time this happens. Looks pretty catastrophic to me. NY is\\nthe finance hub of the world, SF the tech hub of the world... how is this not\\nbad? And all the people living in these gigantic cities? Where are they going\\nto go? No... it's really, really bad!\\n\\n\n",
              "241               0.0  ...                                                                                                                                                           So why is waterfront property still cost so much and getting more expensive?\\nYoud think the property would be worthless knowing what we know. Right? Yeah.\\nExactly. Dont worry youth. You'll be fine.\\n\\n\n",
              "5837              0.0  ...                                                                                                               From what I guess, most likely not but who knows maybe if we are lucky\\nsomething will happen on Earth andthey might be and maybe things will be more\\nmanageable but no one knows for sure, we can just hope for the best when such\\na time comes.\\n\\n\n",
              "20842             0.0  ...                                                                                                                                                                                                                                                                                                                We do something against the rising water though ;D\\n\\n\n",
              "24563             0.0  ...                                                                                                                                                                                                                                                                                                                                                        Or Gambia.\\n\\n\n",
              "1718              1.0  ...                                                                                                                                              Baltics have left the chat Crimea can into island Kallinigrad has left the\\nchat Tunisia has left the chat East Italy has left the chat UK can into\\nArchapeligo Delaware has left the Chat Kuwait has left the chat\\n\\n\n",
              "1710              1.0  ...                                                                                                                                                                                                                                                     Delaware has left the chat Louisiana has left the chat (i have left the chat)\\nRhode Island has left the chat\\n\\n\n",
              "1700              1.0  ...                                                                                                                                                                                                                                       Florida has left the chat  \\nThe Netherlands has left the chat  \\nBangladesh has left the chat  \\nDenmark has left the chat\\n\\n\n",
              "15894             1.0  ...                                                                                                                                                                                                                                                                                           Good thing I don't live in Florida. Now Miami is now just on an island.\\n\\n\n",
              "6265              1.0  ...                                                                                                                                                                                                                                                    you will be one of those sources after a couple more winters and the facts\\nbeat you into humility............\\n\\n\n",
              "12485             2.0  ...                                                                                                                                                                                                                                                Fill a glass with ice cubes, top it off with water, when the ice cubes have\\nmelted the water level will be lower.\\n\\n\n",
              "3253              2.0  ...                                                                                                                                                                                                                                                                                             Melting *SEA* ice does not change sea level. Melting *LAND* ice does.\\n\\n\n",
              "14821             2.0  ...                                                                                                                                                                       JEFFREY G DELABRE not exactly... the melting of ice into the ocean will alter\\nthe salinity... So much so that most ocean life will suffer due to a drastic\\nchange to their environment...\\n\\n\n",
              "23760             2.0  ...                                                                                                                                                                                                                                                                                                                  +Lowmomome you have no idea what else follows...\\n\\n\n",
              "11930             2.0  ...                                                                                                                                                                                                                                                                            Riiiight ... because water flowing off land would not add to the water in the\\noceans.\\n\\n\n",
              "10030             3.0  ...                                                                                                                                                                                                                                                                                            Yep, but real climatologists say the earth is in a 176 year cool down.\\n\\n\n",
              "19044             3.0  ...                                                                                                                                                                                                         Wow is that ever some tangled logic and in any case it's pretty incredible\\nthat there are people who deny the weight of evidence behind climate change .\\n\\n\n",
              "2874              3.0  ...                                                                                                                                                                                                                                                                                       SCIENCE INSIDER  \\n  \\n  \\n  \\n  \\nSAYS BUISNESS INSIDER IN THE CORNER  \\n🤔\\n\\n\n",
              "16007             3.0  ...                                                                                                                                                                                                                                                                                                     Paulo Junior Florida, South Carolina, Denmark and netherlands\\n\\n\n",
              "8673              3.0  ...                                                                                                                                                                                                                                                                                                              it said business insider but this is science insider\\n\\n\n",
              "\n",
              "[20 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKZ3Vn8dVPpz",
        "colab_type": "text"
      },
      "source": [
        "#### Topic distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJASaw68VSug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "99e838c7-48d9-4ff3-d12a-0c05626ebe35"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "\n",
        "topic_count = data_topic_keywords['Dominant_Topic'].value_counts()\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for i, topic in enumerate(topic_count):\n",
        "    y.append(float(topic_count[i]))\n",
        "    x.append('Topic {}'.format(i))\n",
        "\n",
        "ax.bar(x,y)\n",
        "ax.set_title('Topic distribution over comments')\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPd2rfaSVUvv",
        "colab_type": "text"
      },
      "source": [
        "#### Show topic distribution for single comment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-dQc10aVYbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_document_topics = tuned_lda_model.get_document_topics(corpus)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erMnzNzMVbXS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "53b49432-df8f-4633-96a4-0f4c128b3ed2"
      },
      "source": [
        "comment_id = int(input())\n",
        "\n",
        "get_document_topics[comment_id]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "890\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0.38961038), (1, 0.2597403), (2, 0.19480519), (3, 0.15584417)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YxXP5PtAFyV",
        "colab_type": "text"
      },
      "source": [
        "## Contextual Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsVilqF3sfdm",
        "colab_type": "text"
      },
      "source": [
        "### USE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMcWWomT1xa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip3 install seaborn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZvlorA1BsDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['cleaned']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdQI-upW03sj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embeddings = embed(data['cleaned'])\n",
        "\n",
        "print(embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFKuhrPmp4N1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import islice\n",
        "import numpy as np\n",
        "\n",
        "limit = 5\n",
        "\n",
        "for i, comment_embedding in islice(enumerate(np.array(embeddings).tolist()), limit):\n",
        "  print(\"Comment: {}\".format(data['cleaned'][i]))\n",
        "  print(\"Embedding size: {}\".format(len(comment_embedding)))\n",
        "  comment_embedding_snippet = \", \".join(\n",
        "      (str(x) for x in comment_embedding[:3]))\n",
        "  print(\"Embedding: [{}, ...]\\n\".format(comment_embedding_snippet))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8Ysftm5ve2F",
        "colab_type": "text"
      },
      "source": [
        "Plots and prints a heat map showing the semantic contextual similarity. \n",
        "\n",
        "TODO: Try on subset of data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eibwY5QvuYgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "def plot_similarity(labels, features, rotation):\n",
        "  corr = np.inner(features, features)\n",
        "  sns.set(font_scale=1.2)\n",
        "  g = sns.heatmap(\n",
        "      corr,\n",
        "      xticklabels=labels,\n",
        "      yticklabels=labels,\n",
        "      vmin=0,\n",
        "      vmax=1,\n",
        "      cmap=\"YlOrRd\")\n",
        "  g.set_xticklabels(labels, rotation=rotation)\n",
        "  g.set_title(\"Semantic Textual Similarity\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuqstljhCaig",
        "colab_type": "text"
      },
      "source": [
        "Cosine similarity matrix\n",
        "\n",
        "\n",
        "Calculating the cosine angle between two vectors. If two vectors are similar, the angle between them is small, and the cosine similarity value is closer to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsNsiwr5_7JW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def cos_sim(input_vectors):\n",
        "    similarity = cosine_similarity(input_vectors)\n",
        "    return similarity\n",
        "\n",
        "cosine_similarity_matrix = cos_sim(np.array(embeddings))\n",
        "print(cosine_similarity_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzq2XDazCNMi",
        "colab_type": "text"
      },
      "source": [
        "Top N similar comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7fG6YNyDXf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comment = data[\"cleaned\"][492]\n",
        "comment_list = data[\"cleaned\"].tolist()\n",
        "print(comment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiPhdtJrCKZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_top_similar(sentence, sentence_list, similarity_matrix, topN):\n",
        "    # find the index of sentence in list\n",
        "    index = sentence_list.index(sentence)\n",
        "    # get the corresponding row in similarity matrix\n",
        "    similarity_row = np.array(similarity_matrix[index, :])\n",
        "    # get the indices of top similar\n",
        "    indices = similarity_row.argsort()[-topN:][::-1]\n",
        "    return [sentence_list[i] for i in indices]\n",
        "\n",
        "\n",
        "for i, value in enumerate(get_top_similar(comment, comment_list, cosine_similarity_matrix, 5)):\n",
        "  print(\"Top similar comment {}: {}\".format(i+1, value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScRFb3wXVxCJ",
        "colab_type": "text"
      },
      "source": [
        "### BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZUc3fHpVuIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}